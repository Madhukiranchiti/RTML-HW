{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhukiranchiti/RTML-HW/blob/main/Assignment_2_Madhu_RTML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2\n",
        "## Course : Real-Time Machine Learning 5106\n",
        "### Name : Madhu Kiran Chiti\n",
        "### Student ID : 801333676\n",
        "### Github Link :\n"
      ],
      "metadata": {
        "id": "ODAhs7kQ56RM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mpIqH-x4Za6",
        "outputId": "affe103a-d84d-4b62-fe45-21db9fa639cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.2.2\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "!pip install ptflops\n",
        "import ptflops\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "\n",
        "from torch.nn import functional as F\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import MulticlassAccuracy, BinaryAccuracy\n",
        "from torchmetrics import ConfusionMatrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "                                        transforms.ToTensor(),\n",
        "                                      transforms.Resize(64),\n",
        "                                        transforms.Normalize((0.29), (0.32)),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                        transforms.ToTensor(),\n",
        "                                     transforms.Resize(64),\n",
        "                                        transforms.Normalize((0.29), (0.32)),\n",
        "])\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "\n",
        "train_cifar, valid_cifar = random_split(cifar_trainset, [0.8, 0.2])\n",
        "trainLoader = DataLoader(train_cifar, batch_size=256, shuffle=True, num_workers=1)\n",
        "validateLoader = DataLoader(valid_cifar, batch_size=256, shuffle=True, num_workers=1)\n",
        "testLoader = DataLoader(cifar_testset, batch_size=256, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "J3vXxiUu4dHI",
        "outputId": "3ea70b21-cd37-4c88-ba41-8787d48eea33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-16e3a0993959>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_transform = transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Train_Model: # A class to train and save the developed model and the metrics\n",
        "\n",
        "\n",
        "    def __init__(self, model, loss, optimizer, accuracy, model_type, device, classes=0):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model.to(device) ## Setting the model on GPU\n",
        "        self.Loss_Function = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.accuracy = accuracy\n",
        "        self.model_type = model_type\n",
        "        self.classNum = classes\n",
        "\n",
        "        # A dictionary to append or store the results\n",
        "        self.Metrics = {\"Training_Loss\":[],\"Training_Accuracy\":[], \"Validation_Loss\":[], \"Validation_Accuracy\":[],\"Test_Accuracy\":0}\n",
        "        self.ConfMatrix = None\n",
        "\n",
        "    # Function to train the model\n",
        "    def model_run(self, l_data,run_type):\n",
        "\n",
        "        if run_type == 'train':\n",
        "          self.model.train()\n",
        "\n",
        "          if self.model_type == \"Classification\":\n",
        "              MCA = self.accuracy(self.classNum)\n",
        "          else:\n",
        "              MCA = self.accuracy\n",
        "\n",
        "          loss_sum = 0\n",
        "          acc = 0\n",
        "\n",
        "          # Iterates over the data\n",
        "          for data, labels in tqdm(l_data):\n",
        "\n",
        "              # transform data into one-hot vectors\n",
        "              data = data.to(self.device)\n",
        "              if self.model_type == \"Classification\":\n",
        "                  labels = torch.eye(10)[labels]\n",
        "              else:\n",
        "                  labels = labels.reshape(-1, 1)\n",
        "              labels = labels.to(self.device)\n",
        "\n",
        "              predictions = self.model(data)\n",
        "              loss_value = self.Loss_Function(predictions, labels)\n",
        "\n",
        "\n",
        "              self.optimizer.zero_grad()\n",
        "              loss_value.backward()\n",
        "              self.optimizer.step()\n",
        "\n",
        "\n",
        "              # Set the predictions and labels back into integers for accuracy calculation\n",
        "              if self.model_type == \"Classification\":\n",
        "                  predictions = torch.Tensor([torch.argmax(i).item() for i in predictions])\n",
        "                  labels = torch.Tensor([torch.argmax(i).item() for i in labels])\n",
        "\n",
        "              ##### Calculate Loss and accuracy\n",
        "              loss_sum += loss_value.item()\n",
        "              if self.model_type == \"Classification\":\n",
        "                  acc += MCA(predictions, labels)\n",
        "\n",
        "          self.Metrics[\"Training_Loss\"].append(loss_sum / len(l_data))\n",
        "          if self.model_type == \"Classification\":\n",
        "              self.Metrics[\"Training_Accuracy\"].append(acc / len(l_data))\n",
        "\n",
        "\n",
        "        elif run_type == 'eval':\n",
        "          self.model.eval()\n",
        "\n",
        "          if self.model_type == \"Classification\":\n",
        "              MCA = self.accuracy(self.classNum)\n",
        "          else:\n",
        "              MCA = self.accuracy\n",
        "\n",
        "          loss_sum = 0\n",
        "          acc = 0\n",
        "\n",
        "          for data, labels in l_data:\n",
        "\n",
        "              data = data.to(self.device)\n",
        "              if self.model_type == \"Classification\":\n",
        "                  labels = torch.eye(10)[labels]\n",
        "              else:\n",
        "                  labels = labels.reshape(-1, 1)\n",
        "              labels = labels.to(self.device)\n",
        "\n",
        "              with torch.no_grad():\n",
        "                  predictions = self.model(data)\n",
        "              loss_value = self.Loss_Function(predictions, labels)\n",
        "\n",
        "              if self.model_type == \"Classification\":\n",
        "                  predictions = torch.Tensor([torch.argmax(i).item() for i in predictions])\n",
        "                  labels = torch.Tensor([torch.argmax(i).item() for i in labels])\n",
        "\n",
        "              loss_sum += loss_value.item()\n",
        "              if self.model_type == \"Classification\":\n",
        "                  acc += MCA(predictions, labels)\n",
        "\n",
        "          self.Metrics[\"Validation_Loss\"].append(loss_sum / len(l_data))\n",
        "          if self.model_type == \"Classification\":\n",
        "              self.Metrics[\"Validation_Accuracy\"].append(acc / len(l_data))\n",
        "\n",
        "\n",
        "    def fit(self, t_data, v_data, EPOCHS):\n",
        "\n",
        "\n",
        "        for i in range(EPOCHS):\n",
        "\n",
        "            self.model_run(v_data,'eval')\n",
        "            self.model_run(t_data,'train')\n",
        "\n",
        "            print(\"Current Epoch:\", i+1)\n",
        "            print(\"Training_Loss:\", self.Metrics[\"Training_Loss\"][-1], \" | Validation_Loss:\", self.Metrics[\"Validation_Loss\"][-1])\n",
        "            if self.model_type == \"Classification\":\n",
        "                print(\"Training_Accuracy:\", self.Metrics[\"Training_Accuracy\"][-1].item(), \" | Validation_Accuracy:\", self.Metrics[\"Validation_Accuracy\"][-1].item())\n",
        "\n",
        "\n",
        "    def Test_Model(self, testLoader):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        if self.model_type == \"Classification\":\n",
        "            confusion = ConfusionMatrix(task=\"multiclass\", num_classes=self.classNum)\n",
        "            MCA = self.accuracy(self.classNum)\n",
        "        else:\n",
        "            MCA = self.accuracy\n",
        "\n",
        "        predMax = torch.empty(0)\n",
        "        labelMax = torch.empty(0)\n",
        "\n",
        "        for data, labels in testLoader:\n",
        "\n",
        "            data = data.to(self.device)\n",
        "            if self.model_type == \"Classification\":\n",
        "                labels = torch.eye(10)[labels]\n",
        "            else:\n",
        "                labels = labels.reshape(-1, 1)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred = self.model(data)\n",
        "\n",
        "            if self.model_type == \"Classification\":\n",
        "                pred = torch.Tensor([torch.argmax(i).item() for i in pred])\n",
        "                labels = torch.Tensor([torch.argmax(i).item() for i in labels])\n",
        "\n",
        "            predMax = torch.cat((predMax, pred))\n",
        "            labelMax = torch.cat((labelMax, labels))\n",
        "\n",
        "        if self.model_type == \"Classification\":\n",
        "            self.ConfMatrix = confusion(predMax, labelMax)\n",
        "            self.Metrics[\"Test_Accuracy\"] = MCA(predMax, labelMax).item()\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "N7bF2uQLet_n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_cnn(module):\n",
        "  if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)\n"
      ],
      "metadata": {
        "id": "DlbapMLM5FEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@d2l.add_to_class(d2l.Trainer)\n",
        "def __init__(self, max_epochs, num_gpus=1, gradient_clip_val=0):\n",
        "        self.save_hyperparameters()\n",
        "        self.train_loss = []\n",
        "        self.train_acc = []\n",
        "        self.valid_loss = []\n",
        "        self.valid_acc = []\n",
        "\n",
        "        assert num_gpus == 1,'No GPU support yet'\n",
        ""
      ],
      "metadata": {
        "id": "K3GMCbkC5S5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @d2l.add_to_class(d2l.Classifier)\n",
        "def layer_summary(self, X_shape):\n",
        "    X = torch.randn(*X_shape)\n",
        "    for layer in self.net:\n",
        "        X = layer(X)\n",
        "        print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "paCqMy6E5UT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@d2l.add_to_class(d2l.Module)\n",
        "def training_step(self, batch):\n",
        "  l = self.loss(self(*batch[:-1]), batch[-1])\n",
        "  self.plot('loss', l, train=True)\n",
        "  self.train_loss.append(l)\n",
        "  return l\n",
        "\n",
        "#@d2l.add_to_class(d2l.Module)\n",
        "def validation_step(self, batch):\n",
        "  l = self.loss(self(*batch[:-1]), batch[-1])\n",
        "  self.valid_loss.append(l)\n",
        "  self.plot('loss', l, train=False)"
      ],
      "metadata": {
        "id": "cqiJ-bOd5V_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@d2l.add_to_class(d2l.Module)\n",
        "def plot(self, key, value, train):\n",
        "        \"\"\"Plot a point in animation.\"\"\"\n",
        "        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n",
        "        self.board.xlabel = 'epoch'\n",
        "        if train:\n",
        "            x = self.trainer.train_batch_idx / \\\n",
        "                self.trainer.num_train_batches\n",
        "            n = self.trainer.num_train_batches / \\\n",
        "                self.plot_train_per_epoch\n",
        "            metric_type = 'train'\n",
        "        else:\n",
        "            x = self.trainer.epoch + 1\n",
        "            n = self.trainer.num_val_batches / \\\n",
        "                self.plot_valid_per_epoch\n",
        "            metric_type = 'val'\n",
        "        self.board.draw(x, d2l.numpy(d2l.to(value, d2l.cpu())),\n",
        "                        ('train_' if train else 'val_') + key,\n",
        "                        every_n=int(n))\n",
        "\n",
        "        if not train and self.trainer.epoch % 1 == 0:\n",
        "          train_loss = self.trainer.train_loss[-1]\n",
        "          #train_acc = self.trainer.train_acc[-1]\n",
        "          val_loss = self.trainer.valid_loss[-1]\n",
        "          #val_acc = self.trainer.valid_acc[-1]\n",
        "          print(f\"Epoch [{self.trainer.epoch+1}/{self.trainer.epochs}]: \"\n",
        "                f\"train_loss = {train_loss:.4f}, train_acc = {train_acc:.4f}, \")\n",
        "               # f\"val_loss = {val_loss:.4f}, val_acc = {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "EcRcAlNE5YLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@d2l.add_to_class(d2l.Trainer)\n",
        "def fit(self, model, data):\n",
        "        self.prepare_data(data)\n",
        "        self.prepare_model(model)\n",
        "        self.optim = model.configure_optimizers()\n",
        "        self.epoch = 0\n",
        "        self.train_batch_idx = 0\n",
        "        self.val_batch_idx = 0\n",
        "        for self.epoch in range(self.max_epochs):\n",
        "            self.fit_epoch()\n",
        "            self.evaluate()"
      ],
      "metadata": {
        "id": "qreZ0fBb5aEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_to_use = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MNy-szDPfL3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1:"
      ],
      "metadata": {
        "id": "d7Pc1n407GwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "                        padding= 'valid', activation= 'relu',\n",
        "                        input_shape= input_shape,\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(1000, activation= 'relu'))\n",
        "        self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XUxjDqn-7DT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "model = AlexNet((227, 227, 3), num_classes)"
      ],
      "metadata": {
        "id": "ow7YbaGI7Vpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "image_height = 227\n",
        "image_width = 227\n",
        "train_dir = \"./content/train\"\n",
        "valid_dir = \"./content/validation\"\n",
        "model_dir = \"./my_model.h5\""
      ],
      "metadata": {
        "id": "vi88q7t97ZsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale=1./255,\n",
        "                  rotation_range=10,\n",
        "                  width_shift_range=0.1,\n",
        "                  height_shift_range=0.1,\n",
        "                  shear_range=0.1,\n",
        "                  zoom_range=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(image_height, image_width),\n",
        "                                                    color_mode=\"rgb\",\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    seed=1,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode=\"categorical\")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                                    target_size=(image_height, image_width),\n",
        "                                                    color_mode=\"rgb\",\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    seed=7,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode=\"categorical\"\n",
        "                                                    )\n",
        "train_num = train_generator.samples\n",
        "valid_num = valid_generator.samples"
      ],
      "metadata": {
        "id": "WGvU89xU7da4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_arch = AlexNet(((2, 64), (2, 128), (2, 256), (2, 512)))\n",
        "\n",
        "alexnet_Model = Train_Model(alexnet_arch, nn.CrossEntropyLoss(), torch.optim.SGD(alexnet_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "alexnet_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "alexnet_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(alexnet_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"alexnet_Model Train Accuracy:\", alexnet_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"alexnet_Model Test Accuracy:\", alexnet_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "alexnet_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(alexnet_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(alexnet_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(alexnet_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(alexnet_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yBi2YbmH9yJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem** 2:  \n",
        " ResNet-18"
      ],
      "metadata": {
        "id": "IuH3Yvcv9BYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1, dropout_prob=0.0):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)\n",
        ""
      ],
      "metadata": {
        "id": "Hba8wSGX68yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def block(self, num_residuals, num_channels, first_block=False):\n",
        "      blk = []\n",
        "      for i in range(num_residuals):\n",
        "          if i == 0 and not first_block:\n",
        "              blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "          else:\n",
        "              blk.append(Residual(num_channels))\n",
        "      return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10, dropout_prob=0.0):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.dropout_prob = dropout_prob\n",
        "      self.net = nn.Sequential(self.b1())\n",
        "\n",
        "      for i, b in enumerate(arch):\n",
        "          self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "      self.net.add_module('last', nn.Sequential(\n",
        "          nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "          nn.LazyLinear(num_classes)))\n",
        "      self.net.apply(d2l.init_cnn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xp4K54tFCKJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_18_arch = ResNet(((2, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.5)\n",
        "\n",
        "resnet_18_Model = Train_Model(resnet_18_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_18_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_18_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_18_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_18_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-18 Model Train Accuracy:\", resnet_18_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-18 Model Test Accuracy:\", resnet_18_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_18_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QORa8bJFgvr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_18_arch = ResNet(((2, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.6)\n",
        "\n",
        "resnet_18_Model = Train_Model(resnet_18_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_18_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_18_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_18_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_18_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-18 Model Train Accuracy:\", resnet_18_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-18 Model Test Accuracy:\", resnet_18_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_18_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-VXmNIEJB8CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_18_arch = ResNet(((2, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.7)\n",
        "\n",
        "resnet_18_Model = Train_Model(resnet_18_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_18_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_18_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_18_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_18_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-18 Model Train Accuracy:\", resnet_18_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-18 Model Test Accuracy:\", resnet_18_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_18_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_18_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_18_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "eDUIoVPGB-jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline ResNet-11 Model"
      ],
      "metadata": {
        "id": "JqujKNnnQmiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_11_arch = ResNet(((1, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.5)\n",
        "\n",
        "resnet_11_Model = Train_Model(resnet_11_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_11_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_11_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_11_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_11_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-11 Model Train Accuracy:\", resnet_11_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-11 Model Test Accuracy:\", resnet_11_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_11_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Kno2Bat-PCdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_11_arch = ResNet(((1, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.6)\n",
        "\n",
        "resnet_11_Model = Train_Model(resnet_11_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_11_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_11_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_11_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_11_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-11 Model Train Accuracy:\", resnet_11_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-11 Model Test Accuracy:\", resnet_11_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_11_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "jaTkbPZTCCAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_11_arch = ResNet(((1, 64), (2, 128), (2, 256), (2, 512)), dropout_prob=0.7)\n",
        "\n",
        "resnet_11_Model = Train_Model(resnet_11_arch, nn.CrossEntropyLoss(), torch.optim.SGD(resnet_11_arch.parameters(), lr=0.1, momentum=0.9), MulticlassAccuracy, \"Classification\",  device_to_use, 10)\n",
        "\n",
        "t0 = datetime.now()\n",
        "resnet_11_Model.fit(trainLoader, validateLoader, 10)\n",
        "t1 = datetime.now()\n",
        "\n",
        "resnet_11_Model.Test_Model(testLoader)\n",
        "\n",
        "macs, params = get_model_complexity_info(resnet_11_Model.model, (3, 64, 64), as_strings=True, print_per_layer_stat=False, verbose=True)\n",
        "\n",
        "\n",
        "print(\"Time Taken to Train:\", t1 - t0)\n",
        "print(\"ResNet-11 Model Train Accuracy:\", resnet_11_Model.Metrics[\"Training_Accuracy\"][-1].item())\n",
        "print(\"ResNet-11 Model Test Accuracy:\", resnet_11_Model.Metrics[\"Test_Accuracy\"])\n",
        "\n",
        "\n",
        "resnet_11_Model.model.to(\"cpu\")\n",
        "print(f\"Macs:{macs} | Params:{params}\")\n",
        "\n",
        "\n",
        "### PLOTTING METRICS\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Accuracy'], label='Training Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Accuracy'], label='Validation Accuracy')\n",
        "plt.plot(resnet_11_Model.Metrics['Training_Loss'], label='Training Loss')\n",
        "plt.plot(resnet_11_Model.Metrics['Validation_Loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "lnHiXr7ZCDpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}